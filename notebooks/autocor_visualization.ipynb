{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\Documents\\Github\\estancia\\venv\\Lib\\site-packages\\spaghetti\\network.py:41: FutureWarning: The next major release of pysal/spaghetti (2.0.0) will drop support for all ``libpysal.cg`` geometries. This change is a first step in refactoring ``spaghetti`` that is expected to result in dramatically reduced runtimes for network instantiation and operations. Users currently requiring network and point pattern input as ``libpysal.cg`` geometries should prepare for this simply by converting to ``shapely`` geometries.\n",
      "  warnings.warn(dep_msg, FutureWarning, stacklevel=1)\n",
      "c:\\Users\\Miguel\\Documents\\Github\\estancia\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# System management packages\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from numba import NumbaDeprecationWarning\n",
    "\n",
    "sys.path.append('../src')\n",
    "warnings.filterwarnings(action='ignore', category=NumbaDeprecationWarning)\n",
    "\n",
    "# Data science packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "# Geospatial packages\n",
    "import h3\n",
    "import geopandas as gpd\n",
    "from shapely import Polygon\n",
    "from pysal.lib import weights\n",
    "from pysal.explore import esda\n",
    "from splot.esda import moran_scatterplot, lisa_cluster\n",
    "\n",
    "# Personal packages\n",
    "from settings import Settings\n",
    "\n",
    "# Notebook settings\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de fuente de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory and list of files\n",
    "DATA_BASE_DIR = os.path.join(settings.ROOT, 'data')\n",
    "RAW_DATA = os.path.join(DATA_BASE_DIR, 'datos-produccion-maiz')\n",
    "#PROCESSED_DATA = os.path.join(DATA_BASE_DIR, 'maize_production_h3hex_cells')\n",
    "\n",
    "LIST_OF_FILES = [file for file in os.listdir(RAW_DATA)] #if file.startswith('agg')]\n",
    "H3_CATALOGUE = pd.read_csv(os.path.join(RAW_DATA, '01_h3_cells_catalogue.csv'))\n",
    "H3_RESOLUTION_LIST = [col for col in H3_CATALOGUE.columns if col.startswith('hex')]\n",
    "\n",
    "# Declare file selector instance and mesh resolution\n",
    "# file_selector = widgets.Dropdown(\n",
    "#     options=LIST_OF_FILES\n",
    "#     ,description='Files'\n",
    "#     ,disabled=False)\n",
    "\n",
    "# # Display selectors\n",
    "# display(file_selector)\n",
    "\n",
    "file_selector = 'hist-maize-panel-rcp2p6.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pointer: RCP2P6\n"
     ]
    }
   ],
   "source": [
    "# Store file_selector output in variable\n",
    "file_path = os.path.join(RAW_DATA, file_selector)\n",
    "\n",
    "# Extract AIRCCA base model and h3 mesh resolution\n",
    "get_aircca_model = re.compile(r'rcp[0-9]p[0-9]')\n",
    "model_pointer = get_aircca_model.search(file_path).group()\n",
    "\n",
    "print(f'Model pointer: {model_pointer.upper()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 502528 entries, 0 to 2826645\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   lon            502528 non-null  float64\n",
      " 1   lat            502528 non-null  float64\n",
      " 2   year           502528 non-null  int64  \n",
      " 3   mean_precip    502528 non-null  float64\n",
      " 4   mean_precip_2  502528 non-null  float64\n",
      " 5   mean_temp      502528 non-null  float64\n",
      " 6   mean_temp_2    502528 non-null  float64\n",
      " 7   mean_yield     502528 non-null  float64\n",
      " 8   id             502528 non-null  int64  \n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 38.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Load data into dataframe object\n",
    "data = (\n",
    "    pd.read_csv(file_path)\n",
    "    .query(\"year >= 2005 and year <= 2020\")\n",
    "    # .join(\n",
    "    #     other=H3_CATALOGUE[['id'] + H3_RESOLUTION_LIST]\n",
    "    #     ,on='id'\n",
    "    #     ,how='left'\n",
    "    #     ,rsuffix='__ignore')\n",
    ")\n",
    "\n",
    "# Drop __ignore and format column names\n",
    "data.drop(\n",
    "    columns=[col for col in data.columns if col.__contains__('__ignore')]\n",
    "    ,inplace=True)\n",
    "\n",
    "data.columns = [\n",
    "    re.sub(\n",
    "        pattern=r'[-\\. ]'\n",
    "        ,repl='_'\n",
    "        ,string=colname.lower().strip())\n",
    "    for colname in data.columns]\n",
    "\n",
    "# List of ordinary predictors, non geographical nor temporal data\n",
    "ordinary_predictors = [var for var in data.columns if var.startswith('mean')]\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelación espacial global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_yield:2005\n",
      "mean_yield:2006\n",
      "mean_yield:2007\n",
      "mean_yield:2008\n",
      "mean_yield:2009\n",
      "mean_yield:2010\n",
      "mean_yield:2011\n",
      "mean_yield:2012\n",
      "mean_yield:2013\n",
      "mean_yield:2014\n",
      "mean_yield:2015\n",
      "mean_yield:2016\n",
      "mean_yield:2017\n",
      "mean_yield:2018\n",
      "mean_yield:2019\n",
      "mean_yield:2020\n"
     ]
    }
   ],
   "source": [
    "for variable in ['mean_yield']:\n",
    "    for year in data.year.unique():\n",
    "        print(f\"{variable}:{year}\")\n",
    "        # Visualization data\n",
    "        _vis = (\n",
    "            data\n",
    "            .query(f\"year == {year}\")\n",
    "            .assign(geometry=lambda x: gpd.points_from_xy(x.lon, x.lat)))\n",
    "        \n",
    "        # Matriz de pesos bajo criterio de reinas\n",
    "        w = weights.KNN.from_dataframe(\n",
    "            df=_vis,\n",
    "            geom_col=\"geometry\",\n",
    "            silence_warnings=True)\n",
    "        \n",
    "        # Estandarización por renglón\n",
    "        w.set_transform(value='R')\n",
    "\n",
    "        # Calcular columnas de rezago\n",
    "        _vis = (\n",
    "            _vis\n",
    "            .assign(\n",
    "                # Rezago espacial de la variable de interés\n",
    "                lag = lambda _df: weights.spatial_lag.lag_spatial(w=w, y=_df[variable])\n",
    "                # Centrar a la media y escalar a 2 std\n",
    "                ,scaled = lambda _df: (_df[variable] - _df[variable].mean()) / (_df[variable].std() * 2)\n",
    "                ,lag_scaled = lambda _df: (_df.lag - _df.lag.mean()) / (_df.lag.std() * 2)))\n",
    "\n",
    "        # Figure config\n",
    "        fig, ax = plt.subplots(figsize=(16,7))\n",
    "\n",
    "        # Elementos de visualización\n",
    "        sns.regplot(\n",
    "            data=_vis,\n",
    "            x='scaled',\n",
    "            y='lag_scaled',\n",
    "            ci=None,\n",
    "            line_kws=dict(color='tab:red'),\n",
    "            ax=ax)\n",
    "        ax.axvline(0, color='black', linewidth=1, alpha=0.8)\n",
    "        ax.axhline(0, color='black', linewidth=1, alpha=0.8)\n",
    "\n",
    "\n",
    "        # Anotaciones y estilo\n",
    "        ax.set(\n",
    "            title=f'Dispersión de Moran, {year}'\n",
    "            ,xlabel='Variable de análisis'\n",
    "            ,ylabel='Rezago espacial')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f\"../figures/autocor/{variable}/global/glob_autocor_{year}.png\")\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_11132\\3522722676.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images = [imageio.imread(f\"../figures/autocor/{variable}/global/{image}\") for image in image_files]\n"
     ]
    }
   ],
   "source": [
    "variable = \"mean_yield\"\n",
    "\n",
    "# List of image file paths\n",
    "image_files = os.listdir(f'../figures/autocor/{variable}/global/')\n",
    "\n",
    "# Read images and save as GIF\n",
    "images = [imageio.imread(f\"../figures/autocor/{variable}/global/{image}\") for image in image_files]\n",
    "imageio.mimsave(f'../figures/autocor/global_{variable}.gif', images, format='GIF', duration=500, loop=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelación local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_yield:2005\n",
      "mean_yield:2006\n",
      "mean_yield:2007\n",
      "mean_yield:2008\n",
      "mean_yield:2009\n",
      "mean_yield:2010\n",
      "mean_yield:2011\n",
      "mean_yield:2012\n",
      "mean_yield:2013\n",
      "mean_yield:2014\n",
      "mean_yield:2015\n",
      "mean_yield:2016\n",
      "mean_yield:2017\n",
      "mean_yield:2018\n",
      "mean_yield:2019\n",
      "mean_yield:2020\n"
     ]
    }
   ],
   "source": [
    "p = 0.05\n",
    "for variable in ['mean_yield']:\n",
    "    for year in data.year.unique():\n",
    "        print(f\"{variable}:{year}\")\n",
    "        # Visualization data\n",
    "        _vis = (\n",
    "            data\n",
    "            .query(f\"year == {year}\")\n",
    "            .assign(geometry=lambda x: gpd.points_from_xy(x.lon, x.lat)))\n",
    "        \n",
    "        # Matriz de pesos bajo criterio de reinas\n",
    "        w = weights.KNN.from_dataframe(\n",
    "            df=_vis,\n",
    "            geom_col=\"geometry\",\n",
    "            silence_warnings=True)\n",
    "        \n",
    "        # Estandarización por renglón\n",
    "        w.set_transform(value='R')\n",
    "\n",
    "        # Calcular columnas de rezago\n",
    "        _vis = (\n",
    "            _vis\n",
    "            .assign(\n",
    "                # Rezago espacial de la variable de interés\n",
    "                lag = lambda _df: weights.spatial_lag.lag_spatial(w=w, y=_df[variable]),\n",
    "                # Centrar a la media y escalar a 2 std\n",
    "                scaled = lambda _df: (_df[variable] - _df[variable].mean()) / (_df[variable].std() * 2),\n",
    "                lag_scaled = lambda _df: (_df.lag - _df.lag.mean()) / (_df.lag.std() * 2)))\n",
    "\n",
    "        # Estadístico Moran I local\n",
    "        _vis_lisa = esda.moran.Moran_Local(\n",
    "            y=_vis[variable]\n",
    "            ,w=w\n",
    "            ,transformation='R'\n",
    "            ,permutations=1_000\n",
    "            ,n_jobs=-1)\n",
    "        \n",
    "        # Asignar valores de Moran's Local LISAs a datos originales\n",
    "        _vis = _vis.assign(ML_Is=_vis_lisa.Is)\n",
    "\n",
    "        # Figure config\n",
    "        fig, ax = plt.subplots(figsize=(16,7))\n",
    "\n",
    "        # Elementos de visualización\n",
    "        lisa_cluster(\n",
    "            moran_loc=_vis_lisa,\n",
    "            gdf=gpd.GeoDataFrame(_vis),\n",
    "            p=p,\n",
    "            ax=ax,)\n",
    "\n",
    "\n",
    "        # Anotaciones y estilo\n",
    "        ax.set(\n",
    "            title=f'LISA: {p}, {year}',\n",
    "            # xlabel='Variable de análisis',\n",
    "            # ylabel='Rezago espacial'\n",
    "        )\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f\"../figures/autocor/{variable}/local/glob_autocor_{year}.png\")\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_11132\\4222373524.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images = [imageio.imread(f\"../figures/autocor/{variable}/local/{image}\") for image in image_files]\n"
     ]
    }
   ],
   "source": [
    "variable = \"mean_yield\"\n",
    "\n",
    "# List of image file paths\n",
    "image_files = os.listdir(f'../figures/autocor/{variable}/local/')\n",
    "\n",
    "# Read images and save as GIF\n",
    "images = [imageio.imread(f\"../figures/autocor/{variable}/local/{image}\") for image in image_files]\n",
    "imageio.mimsave(f'../figures/autocor/local_{variable}.gif', images, format='GIF', duration=500, loop=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
